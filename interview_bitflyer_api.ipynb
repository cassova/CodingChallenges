{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "**Explain concisely how you would fetch the data from bitflyer.**\n",
    "\n",
    "To collect the data from Bitflyer, I would write a python script that would access the Bitflyer API using the python `requests` library.  Looking at a sample of the results below, I can see the `id` has gaps but I still can use the pagination feature in the API to ensure I get all the data.  On manual execution of the script, I would want to go back in time as far as I can go.  This API has a max of 31 days.  I would increase my `count` to the maximum the API would allow or what is suitable for my bandwidth.  For example, by default it is `100` and the max appears to be `500` (this is about $254B \\times 500 \\approx 124KB$).  Once I get a `count` parameter that's managable, I loop until the API is empty (retrieved all 31 days) by paginating on the `before` parameter as the last `id` on the next request.  After each request, I will store and commit the results into database.  To prevent my IP from being blocked by the API, I would make sure the requests don't exceed `500` requests every `5` minutes.  This would be controlled with a timer and sleep wrapper function.\n",
    "\n",
    "Once I get all the past data, I would turn the script over to a job to run regularly, for example on AWS as a lambda, to get the latest executions.  It would work almost identical as above but instead of going backwards in time, this would go forward in time again using pagination.  The way it would work is to query the database for the latest `id` that was stored and then call the API using the `after` parameter and with the same count as above.  This would also loop till the data was caught up, relying on self-imposed rate limiting to ensure it doesn't exceed the API's rate limits and risk an IP ban.  The amount of data and time to run would determine the frequency of the job.\n",
    "\n",
    "Error handling would also need to be gracefully handled.  The script would need to ensure that a batch of requests is not skipped when added to the database to prevent gaps in data.  The script would also need fail gracefully by reporting exceptions either to a log file or a notification system or both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default count is 100 records\n",
    "# API limit is 500 requests per 5 minutes\n",
    "\n",
    "endpoint = 'https://api.bitflyer.com/v1/'\n",
    "path='executions'\n",
    "query={\"product_code\": \"BTC_JPY\",\"market_type\": \"Spot\", \"count\":999}\n",
    "\n",
    "response = requests.get(f'{endpoint}{path}', params=query)\n",
    "json = response.json()\n",
    "len(json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "**Define the data structures you would use for executions and candles and write functions to process executions and build candles (assume that the data has been already fetched from bitflyer). Please add tests for these functions.**\n",
    "\n",
    "For this work, since I'm working in Python, I am using Pandas DataFrames for the execution and candle data.  I created a function `build_bitflyer_candles` which takes in a json list of dicts and outputs a Pandas DataFrame containing the candles of the given size (default is 1 minute).\n",
    "\n",
    "One thing to note is that this method may not be the ideal approach for this pipeline.  For example, it might be better to store the executions in the database first and then to a query on the database for a specified period and build the candles from that query result to then be stored into another candle table (mentioned below).  If I use this function, it's possible that the JSON will contain incomplete information on the head and tail.  There are a few others options that could be considered such as truncating the json results, removing the first and last candle, etc.\n",
    "\n",
    "In this function, I am assuming buy and sell executions are joined together and treated as separate executions.  The buy/sell direction is not used in the candle creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>number_of_trades</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-07-12 05:42:00</th>\n",
       "      <td>3778572.0</td>\n",
       "      <td>3776049.0</td>\n",
       "      <td>3778422.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3776049.0</td>\n",
       "      <td>0.583183</td>\n",
       "      <td>3.778232e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12 05:43:00</th>\n",
       "      <td>3777720.0</td>\n",
       "      <td>3776314.0</td>\n",
       "      <td>3777592.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3777720.0</td>\n",
       "      <td>0.619797</td>\n",
       "      <td>3.777563e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12 05:44:00</th>\n",
       "      <td>3778650.0</td>\n",
       "      <td>3774549.0</td>\n",
       "      <td>3778650.0</td>\n",
       "      <td>21</td>\n",
       "      <td>3775115.0</td>\n",
       "      <td>2.005997</td>\n",
       "      <td>3.777383e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12 05:45:00</th>\n",
       "      <td>3775500.0</td>\n",
       "      <td>3769996.0</td>\n",
       "      <td>3775500.0</td>\n",
       "      <td>19</td>\n",
       "      <td>3769996.0</td>\n",
       "      <td>1.236068</td>\n",
       "      <td>3.772550e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12 05:46:00</th>\n",
       "      <td>3771044.0</td>\n",
       "      <td>3769568.0</td>\n",
       "      <td>3769996.0</td>\n",
       "      <td>14</td>\n",
       "      <td>3769568.0</td>\n",
       "      <td>1.084558</td>\n",
       "      <td>3.770142e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12 05:47:00</th>\n",
       "      <td>3770974.0</td>\n",
       "      <td>3768369.0</td>\n",
       "      <td>3768871.0</td>\n",
       "      <td>22</td>\n",
       "      <td>3770776.0</td>\n",
       "      <td>1.210800</td>\n",
       "      <td>3.770428e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12 05:48:00</th>\n",
       "      <td>3769082.0</td>\n",
       "      <td>3767418.0</td>\n",
       "      <td>3769000.0</td>\n",
       "      <td>8</td>\n",
       "      <td>3768176.0</td>\n",
       "      <td>0.602000</td>\n",
       "      <td>3.768052e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12 05:49:00</th>\n",
       "      <td>3773251.0</td>\n",
       "      <td>3769624.0</td>\n",
       "      <td>3769624.0</td>\n",
       "      <td>86</td>\n",
       "      <td>3771146.0</td>\n",
       "      <td>9.412095</td>\n",
       "      <td>3.772091e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12 05:50:00</th>\n",
       "      <td>3772993.0</td>\n",
       "      <td>3769631.0</td>\n",
       "      <td>3770625.0</td>\n",
       "      <td>17</td>\n",
       "      <td>3772632.0</td>\n",
       "      <td>1.140688</td>\n",
       "      <td>3.771959e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12 05:51:00</th>\n",
       "      <td>3777039.0</td>\n",
       "      <td>3772666.0</td>\n",
       "      <td>3772666.0</td>\n",
       "      <td>15</td>\n",
       "      <td>3777039.0</td>\n",
       "      <td>0.549522</td>\n",
       "      <td>3.775825e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12 05:52:00</th>\n",
       "      <td>3777777.0</td>\n",
       "      <td>3773668.0</td>\n",
       "      <td>3776873.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3773668.0</td>\n",
       "      <td>1.373582</td>\n",
       "      <td>3.777359e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12 05:53:00</th>\n",
       "      <td>3775790.0</td>\n",
       "      <td>3773278.0</td>\n",
       "      <td>3773278.0</td>\n",
       "      <td>8</td>\n",
       "      <td>3774296.0</td>\n",
       "      <td>0.426295</td>\n",
       "      <td>3.774791e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12 05:54:00</th>\n",
       "      <td>3776576.0</td>\n",
       "      <td>3775593.0</td>\n",
       "      <td>3775593.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3776000.0</td>\n",
       "      <td>1.116555</td>\n",
       "      <td>3.775815e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12 05:55:00</th>\n",
       "      <td>3777039.0</td>\n",
       "      <td>3776873.0</td>\n",
       "      <td>3776873.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3777039.0</td>\n",
       "      <td>9.987400</td>\n",
       "      <td>3.777038e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12 05:56:00</th>\n",
       "      <td>3777777.0</td>\n",
       "      <td>3776803.0</td>\n",
       "      <td>3776803.0</td>\n",
       "      <td>18</td>\n",
       "      <td>3777777.0</td>\n",
       "      <td>3.834911</td>\n",
       "      <td>3.777695e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12 05:57:00</th>\n",
       "      <td>3777777.0</td>\n",
       "      <td>3777489.0</td>\n",
       "      <td>3777777.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3777777.0</td>\n",
       "      <td>1.108254</td>\n",
       "      <td>3.777682e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12 05:58:00</th>\n",
       "      <td>3779702.0</td>\n",
       "      <td>3777776.0</td>\n",
       "      <td>3777776.0</td>\n",
       "      <td>15</td>\n",
       "      <td>3778621.0</td>\n",
       "      <td>5.625615</td>\n",
       "      <td>3.777813e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12 05:59:00</th>\n",
       "      <td>3784905.0</td>\n",
       "      <td>3778857.0</td>\n",
       "      <td>3779959.0</td>\n",
       "      <td>67</td>\n",
       "      <td>3783900.0</td>\n",
       "      <td>5.447236</td>\n",
       "      <td>3.781373e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12 06:00:00</th>\n",
       "      <td>3785000.0</td>\n",
       "      <td>3781368.0</td>\n",
       "      <td>3784999.0</td>\n",
       "      <td>36</td>\n",
       "      <td>3781368.0</td>\n",
       "      <td>3.876335</td>\n",
       "      <td>3.783591e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12 06:01:00</th>\n",
       "      <td>3783020.0</td>\n",
       "      <td>3779928.0</td>\n",
       "      <td>3783020.0</td>\n",
       "      <td>20</td>\n",
       "      <td>3781243.0</td>\n",
       "      <td>2.054109</td>\n",
       "      <td>3.781604e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12 06:02:00</th>\n",
       "      <td>3782862.0</td>\n",
       "      <td>3779973.0</td>\n",
       "      <td>3781591.0</td>\n",
       "      <td>14</td>\n",
       "      <td>3779973.0</td>\n",
       "      <td>0.923088</td>\n",
       "      <td>3.781142e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12 06:03:00</th>\n",
       "      <td>3779805.0</td>\n",
       "      <td>3778000.0</td>\n",
       "      <td>3778000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3779805.0</td>\n",
       "      <td>3.058000</td>\n",
       "      <td>3.778001e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12 06:04:00</th>\n",
       "      <td>3781876.0</td>\n",
       "      <td>3777922.0</td>\n",
       "      <td>3779345.0</td>\n",
       "      <td>45</td>\n",
       "      <td>3777922.0</td>\n",
       "      <td>2.483363</td>\n",
       "      <td>3.779389e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12 06:05:00</th>\n",
       "      <td>3778806.0</td>\n",
       "      <td>3777489.0</td>\n",
       "      <td>3778803.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3777489.0</td>\n",
       "      <td>0.319365</td>\n",
       "      <td>3.778061e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12 06:06:00</th>\n",
       "      <td>3778747.0</td>\n",
       "      <td>3776148.0</td>\n",
       "      <td>3777806.0</td>\n",
       "      <td>11</td>\n",
       "      <td>3778747.0</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>3.776813e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          high        low       open  number_of_trades  \\\n",
       "open_time                                                                \n",
       "2021-07-12 05:42:00  3778572.0  3776049.0  3778422.0                 7   \n",
       "2021-07-12 05:43:00  3777720.0  3776314.0  3777592.0                 9   \n",
       "2021-07-12 05:44:00  3778650.0  3774549.0  3778650.0                21   \n",
       "2021-07-12 05:45:00  3775500.0  3769996.0  3775500.0                19   \n",
       "2021-07-12 05:46:00  3771044.0  3769568.0  3769996.0                14   \n",
       "2021-07-12 05:47:00  3770974.0  3768369.0  3768871.0                22   \n",
       "2021-07-12 05:48:00  3769082.0  3767418.0  3769000.0                 8   \n",
       "2021-07-12 05:49:00  3773251.0  3769624.0  3769624.0                86   \n",
       "2021-07-12 05:50:00  3772993.0  3769631.0  3770625.0                17   \n",
       "2021-07-12 05:51:00  3777039.0  3772666.0  3772666.0                15   \n",
       "2021-07-12 05:52:00  3777777.0  3773668.0  3776873.0                10   \n",
       "2021-07-12 05:53:00  3775790.0  3773278.0  3773278.0                 8   \n",
       "2021-07-12 05:54:00  3776576.0  3775593.0  3775593.0                 9   \n",
       "2021-07-12 05:55:00  3777039.0  3776873.0  3776873.0                10   \n",
       "2021-07-12 05:56:00  3777777.0  3776803.0  3776803.0                18   \n",
       "2021-07-12 05:57:00  3777777.0  3777489.0  3777777.0                 9   \n",
       "2021-07-12 05:58:00  3779702.0  3777776.0  3777776.0                15   \n",
       "2021-07-12 05:59:00  3784905.0  3778857.0  3779959.0                67   \n",
       "2021-07-12 06:00:00  3785000.0  3781368.0  3784999.0                36   \n",
       "2021-07-12 06:01:00  3783020.0  3779928.0  3783020.0                20   \n",
       "2021-07-12 06:02:00  3782862.0  3779973.0  3781591.0                14   \n",
       "2021-07-12 06:03:00  3779805.0  3778000.0  3778000.0                 4   \n",
       "2021-07-12 06:04:00  3781876.0  3777922.0  3779345.0                45   \n",
       "2021-07-12 06:05:00  3778806.0  3777489.0  3778803.0                 6   \n",
       "2021-07-12 06:06:00  3778747.0  3776148.0  3777806.0                11   \n",
       "\n",
       "                         close    volume       average  \n",
       "open_time                                               \n",
       "2021-07-12 05:42:00  3776049.0  0.583183  3.778232e+06  \n",
       "2021-07-12 05:43:00  3777720.0  0.619797  3.777563e+06  \n",
       "2021-07-12 05:44:00  3775115.0  2.005997  3.777383e+06  \n",
       "2021-07-12 05:45:00  3769996.0  1.236068  3.772550e+06  \n",
       "2021-07-12 05:46:00  3769568.0  1.084558  3.770142e+06  \n",
       "2021-07-12 05:47:00  3770776.0  1.210800  3.770428e+06  \n",
       "2021-07-12 05:48:00  3768176.0  0.602000  3.768052e+06  \n",
       "2021-07-12 05:49:00  3771146.0  9.412095  3.772091e+06  \n",
       "2021-07-12 05:50:00  3772632.0  1.140688  3.771959e+06  \n",
       "2021-07-12 05:51:00  3777039.0  0.549522  3.775825e+06  \n",
       "2021-07-12 05:52:00  3773668.0  1.373582  3.777359e+06  \n",
       "2021-07-12 05:53:00  3774296.0  0.426295  3.774791e+06  \n",
       "2021-07-12 05:54:00  3776000.0  1.116555  3.775815e+06  \n",
       "2021-07-12 05:55:00  3777039.0  9.987400  3.777038e+06  \n",
       "2021-07-12 05:56:00  3777777.0  3.834911  3.777695e+06  \n",
       "2021-07-12 05:57:00  3777777.0  1.108254  3.777682e+06  \n",
       "2021-07-12 05:58:00  3778621.0  5.625615  3.777813e+06  \n",
       "2021-07-12 05:59:00  3783900.0  5.447236  3.781373e+06  \n",
       "2021-07-12 06:00:00  3781368.0  3.876335  3.783591e+06  \n",
       "2021-07-12 06:01:00  3781243.0  2.054109  3.781604e+06  \n",
       "2021-07-12 06:02:00  3779973.0  0.923088  3.781142e+06  \n",
       "2021-07-12 06:03:00  3779805.0  3.058000  3.778001e+06  \n",
       "2021-07-12 06:04:00  3777922.0  2.483363  3.779389e+06  \n",
       "2021-07-12 06:05:00  3777489.0  0.319365  3.778061e+06  \n",
       "2021-07-12 06:06:00  3778747.0  0.955000  3.776813e+06  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def build_bitflyer_candles(json, candle_size='1min'):\n",
    "    '''\n",
    "    Builds candles dataframe from BitFlyer API json input.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    json : list(dict())\n",
    "        The json response from bitflyer\n",
    "    \n",
    "    size : string, optional\n",
    "        Candle size.  (Default is 1 minute)\n",
    "        Uses Panda's offset aliases. For more details, read here:\n",
    "        https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        Columns: high,low,open,close,number_of_trades,volume,average\n",
    "        Index: open_time (of each candle)\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> build_candles(json, 'T')\n",
    "     <Pandas DataFrame with 1 minute candles>\n",
    "     \n",
    "    >>> build_candles(json, '15min')\n",
    "     <Pandas DataFrame with 15 minute candles>\n",
    "     \n",
    "    >>> build_candles(json, '1h')\n",
    "     <Pandas DataFrame with 1 hour candles>\n",
    "     \n",
    "    >>> build_candles(json, '1d')\n",
    "     <Pandas DataFrame with 1 day candles>\n",
    "    '''\n",
    "    \n",
    "    # Build a Pandas Dataframe with exec_date as the index\n",
    "    df=pd.DataFrame(json)\n",
    "    df.exec_date = pd.to_datetime(df.exec_date)\n",
    "    df.set_index('exec_date',inplace=True)\n",
    "    df.sort_index(inplace=True) # needed for the merge_asof later\n",
    "\n",
    "    # Add open, high, low, close prices\n",
    "    group = df.groupby(pd.Grouper(freq=candle_size)) # group by minute\n",
    "    minute_df = group['price'].agg({'first','min','max','last','count'})\n",
    "    \n",
    "    # Merge volume with prices\n",
    "    minute_df = minute_df.merge(group['size'].sum(),how='left',left_index=True, right_index=True)\n",
    "    minute_df.rename(columns={'min':'low','max':'high','last':'close','first':'open','size':'volume','count':'number_of_trades'},inplace=True)\n",
    "\n",
    "    # Fill N/A prices with last close  - average will remain zero for these records\n",
    "    minute_df.close = minute_df.close.ffill()\n",
    "    na_cols = ['open','high','low']\n",
    "    for c in na_cols:\n",
    "        minute_df[c] = minute_df[c].fillna(minute_df.close)\n",
    "    \n",
    "    # Calculate the weighted price\n",
    "    wp_df = pd.merge_asof(df, minute_df.volume, on='exec_date').set_index('exec_date')\n",
    "    wp_df['average'] = (wp_df['size']/wp_df['volume'])*wp_df['price']\n",
    "    wp_group = wp_df.groupby(pd.Grouper(freq=candle_size))\n",
    "    minute_df = minute_df.merge(wp_group['average'].sum(),how='left',left_index=True, right_index=True)\n",
    "    \n",
    "    # Rename index as \"open_time\"\n",
    "    minute_df.index.name = 'open_time'\n",
    "    \n",
    "    return minute_df\n",
    "\n",
    "df = build_bitflyer_candles(json, '1min')\n",
    "display(df[:50])\n",
    "\n",
    "validate_columns = ['high','low','open','close','number_of_trades','volume','average']\n",
    "\n",
    "assert len(df)>0, \"Dataframe is empty\"\n",
    "assert df.index.name == 'open_time', \"Index is not open_time\"\n",
    "assert type(df.index) == pd.DatetimeIndex, \"Index is not of type pandas DatetimeIndex\"\n",
    "assert len(df.columns) == len(validate_columns), \"Number of columns doesn't match\"\n",
    "assert all(c in df.columns for c in validate_columns), \"Missing necessary columns\"\n",
    "assert all(df.notnull()), \"There are null values\"\n",
    "assert len(df)!=(df.index.max()-df.index.min()).seconds//60, \"Number of records doesn't match the number of minutes between the first and last timestamp\"\n",
    "assert all(df.high>=df.low), \"The high price has values lower than the low price\"\n",
    "assert all(df.high>=df.open), \"The high price has values lower than the open price\"\n",
    "assert all(df.high>=df.close), \"The high price has values lower than the close price\"\n",
    "assert all(df.high>=df.average), \"The high price has values lower than the average price\"\n",
    "assert all(df.low<=df.open), \"The low price has values higher than the open price\"\n",
    "assert all(df.low<=df.close), \"The low price has values higher than the close price\"\n",
    "assert all((df.low<=df.average) | (df.volume==0)), \"The low price has values higher than the average price\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "**Suggest a postgresql schema and sql queries to store the executions and candles. The schema must take into account the queries of the following question.**\n",
    "\n",
    "\n",
    "The following PostgreSQL table would hold all the executions for `BTC_JPY` from the BitFlyer API. The `side` variable was reduced to a single character and could be reduced further to a boolean if desired (e.g. `buy`).  The `buy_child_id` and `sell_child_id` columns were made variable because this data could be removed if proved unuseful or to handle changes in structure from BitFlyer.  The `create_date` timestamp was added for a minimal amount of change control tracking across all tables.  Additional columns like `create_user`, `mod_date`, and `mod_user` could also be added if additional change tracking was needed.  The primary key for this table with the `id` from the BitFlyer API.\n",
    "\n",
    "```postgresql\n",
    "CREATE TABLE public.bitflyer_executions_btcjpy (\n",
    "    id int(8) NOT NULL,\n",
    "    side char(1) NOT NULL,             -- 'B' = buy | 'S' = sell\n",
    "    exec_date timestamp NOT NULL,\n",
    "    price numeric(20, 8) NOT NULL,\n",
    "    volume numeric(20, 8) NOT NULL,    -- size of execution\n",
    "    buy_child_id VARCHAR(30) NULL,\n",
    "    sell_child_id VARCHAR(30) NULL,\n",
    "    create_date timestamptz NOT NULL DEFAULT now(),\n",
    "    CONSTRAINT bitflyer_executions_btcjpy_pkey PRIMARY KEY (id)\n",
    ");\n",
    "```\n",
    "\n",
    "The following PostgreSQL tables would hold all the candlestick data for `BTC_JPY` calculated from the BitFlyer executions.  The reason this is all in one table is because candlestick data is usually lightweight.  Growth would most likely occur in the currency pairs so that data dimension would be separated by table instead of kept in one table.  Also, different sources of data could be added in the future (for example Binance data would be stored in another table).  This also aligns with the `bitflyer_executions_btcjpy` table.  The `size_id` will determine what size of candlestick.  For data integrity and to limit space consumption, this value is stored in another table and is linked by a foreign key.\n",
    "\n",
    "```postgresql\n",
    "CREATE TABLE public.bitflyer_candlesticks_btcjpy (\n",
    "    size_id int2 NOT NULL,             -- e.g. 0 = 1min, 1 = 15min, 2 = 1h, etc..\n",
    "    open_time timestamp NOT NULL,\n",
    "    \"open\" numeric(20, 8) NOT NULL,\n",
    "    high numeric(20, 8) NOT NULL,\n",
    "    low numeric(20, 8) NOT NULL,\n",
    "    \"close\" numeric(20, 8) NOT NULL,\n",
    "    \"average\" numeric(20, 8) NOT NULL,\n",
    "    volume numeric(20, 8) NOT NULL,\n",
    "    number_of_trades int4 NOT NULL,\n",
    "    create_date timestamptz NOT NULL DEFAULT now(),\n",
    "    CONSTRAINT bitflyer_candlesticks_btcjpy_pkey PRIMARY KEY (size_id, open_time),\n",
    "    CONSTRAINT bitflyer_candlesticks_btcjpy_size_fk FOREIGN KEY (size_id) REFERENCES public.candlestick_sizes(id)\n",
    ");\n",
    "```\n",
    "\n",
    "To support the foreign key and data integrity, the following table would also be created:\n",
    "\n",
    "```postgresql\n",
    "CREATE TABLE public.candlestick_sizes (\n",
    "    id int2 NOT NULL,                  -- e.g. 0, 1, 2, etc..\n",
    "    \"size\" VARCHAR(30) NOT NULL,         -- e.g. 1min, 15min, 1h, etc...\n",
    "    create_date timestamptz NOT NULL DEFAULT now(),\n",
    "    CONSTRAINT candlestick_sizes_pkey PRIMARY KEY (id)\n",
    ");\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4\n",
    "\n",
    "**Suggest efficient sql queries to handle the following:**\n",
    "\n",
    "1. find the daily minimum and maximum price over the last 30 days\n",
    "2. find the daily volume of executions that happened over and under a given price (parameter) for the last 30 days\n",
    "\n",
    "**Query 1**\n",
    "\n",
    "Suggested approach:\n",
    "```postgresql\n",
    "SELECT date_trunc('day', exec_date) as date,\n",
    "       MIN(price) as min_price,\n",
    "       MAX(price) as max_price\n",
    " FROM bitflyer_executions_btcjpy\n",
    "WHERE exec_date >= (CURRENT_DATE - INTERVAL '30 days')\n",
    "GROUP BY date\n",
    "ORDER BY date\n",
    "```\n",
    "\n",
    "Alternative approach:\n",
    "```postgresql\n",
    "SELECT date_trunc('day', exec_date) as date,\n",
    "       MIN(low) as min_price,\n",
    "       MAX(high) as max_price\n",
    " FROM bitflyer_candlesticks_btcjpy\n",
    "WHERE open_time >= (CURRENT_DATE - INTERVAL '30 days')\n",
    "  AND size_id = 0  -- Assume 0 = 1min\n",
    "GROUP BY date\n",
    "ORDER BY date\n",
    "```\n",
    "\n",
    "**Query 2**\n",
    "\n",
    "```postgresql\n",
    "SELECT DATE_TRUNC('day', exec_date) as date,\n",
    "       COALESCE(SUM(CASE WHEN price <= :price THEN volume END),0) as \"under_volume\",\n",
    "       COALESCE(SUM(CASE WHEN price > :price THEN volume END),0) as \"over_volume\"\n",
    " FROM bitflyer_executions_btcjpy\n",
    "WHERE exec_date >= (CURRENT_DATE - INTERVAL '30 days')\n",
    "GROUP BY date\n",
    "ORDER BY date\n",
    "```\n",
    "\n",
    "*Assumption:* Executions matching the price parameter will be placed in the `under_volume` bucket."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
